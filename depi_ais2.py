# -*- coding: utf-8 -*-
"""DEPI AIS2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/depi-ais2-5a8990b2-65f4-4092-b7b4-35d1b389c2cf.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250128/auto/storage/goog4_request%26X-Goog-Date%3D20250128T183933Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D7f0795e5774fd4569d9396776721092d1016e4743c131f1e9f754bf4d1a22c4bda5d7cd90cf3b3f940ca95cb9367afc2e2380d5dd49198e214c74f46d8c2f93c7a2cf17ee6bdae5a001a138f78d235bdf0ec15cb556e1c11059c67a150ab9ffa8fe3f36e9a5b915f6a011e370df7f88da4fb2453f8b0c886361bd565cadb51b37e271143ff56c8a6f63366ecc2ad4cd884af1f1a103758f40760ef128f4104753b33ee1b5493a0c46af4c9ddf01ff2ff80606033accb19e5202565fae57b6b453cd01a4883ba491fee78d39453d0b28787a9f889a9851b19e5d889ee1f8d6a652be811a34ce82e9aa8e9177ed8801ae1fabe19fc03c19546ad801c41332f6fed
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
fedesoriano_heart_failure_prediction_path = kagglehub.dataset_download('fedesoriano/heart-failure-prediction')

print('Data source import complete.')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, ExtraTreesClassifier, AdaBoostClassifier, VotingClassifier, StackingClassifier
from xgboost import XGBClassifier
from catboost import CatBoostClassifier
from lightgbm import LGBMClassifier

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

df = pd.read_csv('/kaggle/input/heart-failure-prediction/heart.csv')

df.head()

df.info()

"""### **Preprocessing**"""

columns_to_remove = ['ExerciseAngina', 'Oldpeak', 'RestingECG', 'ChestPainType','ST_Slope']

# Drop the columns
df = df.drop(columns=columns_to_remove, axis=1)

X = df.drop(columns=['HeartDisease'])
y = df['HeartDisease']

X

y

encoder = LabelEncoder()

X['Sex'] = encoder.fit_transform(X['Sex'])
# X['ChestPainType'] = encoder.fit_transform(X['ChestPainType'])
# X['RestingECG'] = encoder.fit_transform(X['RestingECG'])
# X['ExerciseAngina'] = encoder.fit_transform(X['ExerciseAngina'])
# X['ST_Slope'] = encoder.fit_transform(X['ST_Slope'])

X

X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)

"""### **Data Modeling**"""

lr = LogisticRegression()

lr.fit(X_train, y_train)

lr.score(X_train, y_train)

y_pred = lr.predict(X_test)

print(accuracy_score(y_test, y_pred))

svm = SVC(C=10)

svm.fit(X_train, y_train)

svm.score(X_train, y_train)

y_pred = svm.predict(X_test)

print(accuracy_score(y_test, y_pred))

rf = RandomForestClassifier(n_estimators=10, max_depth=6)

rf.fit(X_train, y_train)

rf.score(X_train, y_train)

y_pred = rf.predict(X_test)

print(accuracy_score(y_test, y_pred))

estimator = DecisionTreeClassifier(max_depth=6, min_samples_split=0.2)

bagg = BaggingClassifier(estimator=estimator, n_estimators=10)

bagg.fit(X_train, y_train)

bagg.score(X_train, y_train)

y_pred = bagg.predict(X_test)

print(accuracy_score(y_test, y_pred))

trees = ExtraTreesClassifier(n_estimators=10, max_depth=6)

trees.fit(X_train, y_train)

trees.score(X_train, y_train)

y_pred = trees.predict(X_test)

print(accuracy_score(y_test, y_pred))

xgb = XGBClassifier(n_estimators=5)

xgb.fit(X_train, y_train)

xgb.score(X_train, y_train)

y_pred = xgb.predict(X_test)

print(accuracy_score(y_test, y_pred))

est = LogisticRegression()
ada = AdaBoostClassifier(estimator=est, n_estimators=5)

ada.fit(X_train, y_train)

ada.score(X_train, y_train)

ada.score(X_test, y_test)

cat = CatBoostClassifier(n_estimators=10,max_depth=6)

cat.fit(X_train, y_train)

cat.score(X_train, y_train)

cat.score(X_test, y_test)

lgbm = LGBMClassifier(n_estimators=10)

lgbm.fit(X_train, y_train)

lgbm.score(X_train, y_train)

lgbm.score(X_test, y_test)

